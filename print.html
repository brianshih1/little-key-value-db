<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Building a Transactional Key-Value database</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter_1/motivation.html"><strong aria-hidden="true">1.</strong> Motivation</a></li><li class="chapter-item expanded "><a href="chapter_2/database_api.html"><strong aria-hidden="true">2.</strong> Database API</a></li><li class="chapter-item expanded "><a href="chapter_3/core_concepts.html"><strong aria-hidden="true">3.</strong> Core Concepts</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chapter_3/mvcc.html"><strong aria-hidden="true">3.1.</strong> MVCC</a></li><li class="chapter-item expanded "><a href="chapter_3/interleave_txns.html"><strong aria-hidden="true">3.2.</strong> Concurrency Anomalies</a></li><li class="chapter-item expanded "><a href="chapter_3/dealing_with_anomalies.html"><strong aria-hidden="true">3.3.</strong> Dealing with Anomalies</a></li><li class="chapter-item expanded "><a href="chapter_3/read_refresh.html"><strong aria-hidden="true">3.4.</strong> Read Refresh</a></li><li class="chapter-item expanded "><a href="chapter_3/hybrid_logical_clock.html"><strong aria-hidden="true">3.5.</strong> Hybrid Logical Clock</a></li></ol></li><li class="chapter-item expanded "><a href="chapter_4/life_of_a_query.html"><strong aria-hidden="true">4.</strong> Life of A Query</a></li><li class="chapter-item expanded "><a href="chapter_5/implementation_details.html"><strong aria-hidden="true">5.</strong> Implementation Details</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chapter_5/mvcc_implementation.html"><strong aria-hidden="true">5.1.</strong> MVCC</a></li><li class="chapter-item expanded "><a href="chapter_5/latch_manager.html"><strong aria-hidden="true">5.2.</strong> Latch Manager</a></li><li class="chapter-item expanded "><a href="chapter_5/lock_table.html"><strong aria-hidden="true">5.3.</strong> Lock Table</a></li><li class="chapter-item expanded "><a href="chapter_5/timestamp_oracle.html"><strong aria-hidden="true">5.4.</strong> Timestamp Oracle</a></li><li class="chapter-item expanded "><a href="chapter_5/deadlock_detection.html"><strong aria-hidden="true">5.5.</strong> Deadlock Detection</a></li><li class="chapter-item expanded "><a href="chapter_5/concurrency_manager.html"><strong aria-hidden="true">5.6.</strong> Concurrency Manager</a></li><li class="chapter-item expanded "><a href="chapter_5/request.html"><strong aria-hidden="true">5.7.</strong> Executing the Request</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Building a Transactional Key-Value database</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="motivation"><a class="header" href="#motivation">Motivation</a></h1>
<p><em>Richard Feynman - “What I cannot create, I do not understand”</em></p>
<p>As someone without a background in databases, I’ve always been curious about the inner workings of transactions in databases such as PostgreSQL and CockroachDB. To better understand this, I decided to build my own transactional key-value database.</p>
<p>Rather than trying to reinvent the wheel, I studied CockroachDB extensively and followed its architecture as closely as possible. For those of you who aren't familiar with what CockroachDB is, it is a distributed SQL database built on top of a transactional key-value store. By following the architecture of CockroachDB's key-value store, I was able to learn in a more structured manner and study its design patterns.</p>
<p>Here is a quick summary of the database I built:</p>
<ul>
<li>key-value database</li>
<li>thread-safe</li>
<li>uses RocksDB as the storage engine</li>
<li>written in Rust (my first time learning Rust!)</li>
<li>support transactions</li>
<li>SSI (serializable Snapshot Isolation)</li>
<li>uses MVCC (multi-version concurrency control)</li>
<li>uses pessimistic write locks and optimistic reads (reads are lock-free)</li>
</ul>
<p>My motivation for writing this blog series is to solidify my understanding of the project. In this blog series, I will explain the theory behind the database and dive into the implementation details. I will also provide references and summaries for CockroachDB's repo.</p>
<p>The source code is available on GitHub (PRs/suggestions welcome) <a href="https://github.com/brianshih1/little-key-value-db">here</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="database-api"><a class="header" href="#database-api">Database API</a></h1>
<p>Let’s first talk about the API of the toy database. The database’s API consists of the following methods:</p>
<ul>
<li>set_time</li>
<li>begin_txn</li>
<li>write</li>
<li>read</li>
<li>read_without_txn</li>
<li>abort_txn</li>
<li>commit_txn</li>
<li>run_txn</li>
</ul>
<p>Here is an example of using the database:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let db = DB::new(&quot;./tmp/data&quot;, Timestamp::new(10))
let txn1 = db.begin_txn().await;
let value = db.read::&lt;i32&gt;(&quot;foo&quot;, txn1).await.unwrap();
if value == &quot;bar&quot; {
	db.write(&quot;baz&quot;, 20, txn1).await.unwrap();
}
let commit_result = db.commit_txn(txn1).await;
<span class="boring">}</span></code></pre></pre>
<p>In the code snippet above, we created a database by providing a path to specify where to store the records. We then began a transaction, performed a write and a read, then committed the transaction.</p>
<p>An alternative way to perform transactions is with the <code>run_txn</code> method. In the snippet below, the <code>run_txn</code> function automatically begins a transaction and commits the transaction at the end of the function scope. It would also abort the transaction if the inner function panics.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>db.run_txn(|txn_context| async move {
		let value = txn_context.read::&lt;i32&gt;(&quot;foo&quot;).await;
		if value == &quot;bar&quot; {
	    txn_context.write(&quot;foo&quot;, 12).await.unwrap();
    }
})
<span class="boring">}</span></code></pre></pre>
<p>For more examples, feel free to check out the <a href="https://github.com/brianshih1/little-key-value-db/blob/master/src/db/db_test.rs">unit tests</a> I wrote for my database.</p>
<h3 id="thread-safe"><a class="header" href="#thread-safe">Thread-safe</a></h3>
<p>The database is thread-safe. If you wrap the database instance around an <code>Arc</code>, you can safely use it across different threads. For example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let db = Arc::new(DB::new(&quot;./tmp/data&quot;, Timestamp::new(10)));

let db_1 = Arc::clone(db);
let key1 = &quot;foo&quot;;
let key2 = &quot;bar&quot;;
let task_1 = tokio::spawn(async move {
    db_1.run_txn(|txn_context| async move {
        txn_context.write(key1, 1).await.unwrap();
				txn_context.write(key2, 10).await.unwrap();
    })
    .await
});

let db_2 = Arc::clone(db);
let task_2 = tokio::spawn(async move {
    db_2.run_txn(|txn_context| async move {
        txn_context.write(key1, 2).await.unwrap();
				txn_context.write(key2, 20).await.unwrap();
    })
    .await;
});
tokio::try_join!(task_1, task_2).unwrap();
<span class="boring">}</span></code></pre></pre>
<p>In the example above, the serializability of the database guarantees that either all of <code>task1</code> is executed first or all of <code>task2</code> is executed first.</p>
<h3 id="time"><a class="header" href="#time">Time</a></h3>
<p>The database is powered by a Hybrid Logical Clock (which we will cover later). The developer must manually increment the physical time with the set_time function. But it can also be swapped out with an implementation that uses the system’s time instead.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h1>
<p>Atomicity and isolation are two important traits of transactional databases.</p>
<ul>
<li>Atomicity: all of the database operations in a transaction are executed as a single unit (either all of them or none of them are performed).</li>
<li>Isolation: transactions don’t see intermediate changes of other transactions.</li>
</ul>
<p>To guarantee atomicity and isolation, I borrowed many concepts from CockroachDB’s architecture, which they outlined in <a href="https://www.cockroachlabs.com/guides/thank-you/?pdf=/pdf/cockroachdb-the-resilient-geo-distributed-sql-database-sigmod-2020.pdf">their research paper</a>. The relevant sections include sections 3.2  (Atomicity Guarantees), section 3.3 (Concurrency Control), and section 3.24 (Read Refreshes).</p>
<p>In general, here are some of the core techniques I used to implement transactions</p>
<ul>
<li>MVCC</li>
<li>Write Intents</li>
<li>Pessimistic writes and optimistic reads</li>
<li>Read refreshes</li>
</ul>
<p>Other parts of the blog series will cover topics like the internals of concurrency control, deadlock detection, and hybrid-logical clock.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mvcc"><a class="header" href="#mvcc">MVCC</a></h1>
<p>Multiversion concurrency control (MVCC) is an optimization technique used by databases to improve the performance of concurrent operations. The idea behind MVCC is that the database stores multiple versions for each record.</p>
<p>When a record is updated or added, a new entry in the database is added instead of overwriting the original entry. Database reads are performed at a certain version or timestamp. The database returns the most up-to-date record less than or equal to the specified read version.</p>
<p>In the example below, there are 3 different versions of the “Apple” key, each with a different timestamp. The read is performed at timestamp 15. The database returns the result at timestamp 10 since that is the record with the largest timestamp less than 15.</p>
<img src="chapter_3/../images/mvcc.png" width="65%">
<h3 id="write-intent"><a class="header" href="#write-intent">Write Intent</a></h3>
<p>A single transaction may perform multiple writes. Before the transaction is committed, the uncommitted writes must not be read by other transactions. To address this problem, write intent is introduced (I learned about this concept from CockroachDB).</p>
<p>A write intent is a record stored in the MVCC database to represent uncommitted writes. It is given an INTENT timestamp that distinguishes it from normal timestamps. Each key must only have at most one write intent.</p>
<img src="chapter_3/../images/write_intent.png" width="55%">
<p>In the example above, there is an uncommitted write with an INTENT timestamp for the &quot;Apple&quot; key. The table stores additional metadata, including the transaction ID and the write timestamp, for the write intent.</p>
<h3 id="transaction-record"><a class="header" href="#transaction-record">Transaction Record</a></h3>
<p>A transaction may create multiple write intents. The visibility of the uncommitted intent for a transaction must be flipped atomically. This is the job of <em>transaction records</em>.</p>
<p>The database stores a transaction record for each transaction in a separate database namespace. The key of the transaction records is the transaction ID and the value contains the status and timestamp for each transaction.</p>
<p>When the transaction is committed, the transaction record is marked as committed. All the write intents are readable by other transactions at this moment.</p>
<img src="chapter_3/../images/txn_record.png" width="50%">
<p>The timestamp in a committed transaction record is the transactions commit timestamp. Since each timestamp in the database is guaranteed to be unique, each committed transaction has a unique commit timestamp. This guarantees serial execution order of transactions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concurrency-anomalies"><a class="header" href="#concurrency-anomalies">Concurrency Anomalies</a></h1>
<p>For those familiar with concepts like read-write, write-write, and write-read anomalies, feel free to skip this section!</p>
<h3 id="interleaving-transactions"><a class="header" href="#interleaving-transactions">Interleaving transactions</a></h3>
<p>Databases are allowed to interleave transactions as long as isolation and atomicity are maintained. In other words, it just has to maintain the illusion that the transactions are performed sequentially.</p>
<p>For example, suppose we interleave the following two transactions as follows:</p>
<img src="chapter_3/../images/interleave_1.png" width="55%">
<p>The output of the above ordering is exactly the same as the ordering below. Therefore, the schedule above is a Serializable Schedule, since it is equivalent to some serial execution.</p>
<img src="chapter_3/../images/interleave_2.png" width="55%">
<h3 id="transaction-anomalies"><a class="header" href="#transaction-anomalies">Transaction anomalies</a></h3>
<p>Interleaving transactions may lead to anomalies that break the database’s isolation and atomicity guarantees. There are 3 main types of anomalies:</p>
<ul>
<li>read-write conflict</li>
<li>write-read conflict</li>
<li>write-write conflict</li>
</ul>
<h3 id="read-write-conflict"><a class="header" href="#read-write-conflict">Read-write conflict</a></h3>
<p>Also known as unrepeatable reads. This happens when two reads of the same transaction yield different results even though the transaction is not responsible for the change in value.</p>
<img src="chapter_3/../images/read_write.png" width="55%">
<h3 id="write-read-conflict"><a class="header" href="#write-read-conflict">Write-read conflict</a></h3>
<p>Also known as dirty read. This happens when a transaction reads an uncommitted write by another transaction.</p>
<img src="chapter_3/../images/write_read.png" width="55%">
<h3 id="write-write-conflict"><a class="header" href="#write-write-conflict">Write-write conflict</a></h3>
<p>Also known as overwriting uncommitted data or lost update. This happens when a transaction overwrites another transaction’s uncommitted write. In this example, T1’s first write to key A is lost when transaction 2 commits.</p>
<img src="chapter_3/../images/write_write.png" width="55%">
<div style="break-before: page; page-break-before: always;"></div><h1 id="dealing-with-anomalies"><a class="header" href="#dealing-with-anomalies">Dealing with Anomalies</a></h1>
<p>CockroachDB outlined its strategy to deal with transaction conflicts in section 3.3 of <a href="https://www.cockroachlabs.com/guides/thank-you/?pdf=/pdf/cockroachdb-the-resilient-geo-distributed-sql-database-sigmod-2020.pdf">its research paper</a>. My database uses the same concurrency control techniques outlined in that section.</p>
<h3 id="commit-timestamp"><a class="header" href="#commit-timestamp">Commit Timestamp</a></h3>
<p>Each transaction performs its reads and writes at its commit timestamp. This is what guarantees the serializability of transactions. This section covers how a transaction determines its commit timestamp.</p>
<p>A transaction has a read timestamp and a write timestamp. The read/write timestamps are initialized to the timestamp when the transaction is created, which is guaranteed to be unique. The transaction stores the most recent write timestamp as part of the write intent. When the transaction commits, the final write timestamp is used as the commit timestamp.</p>
<p>Usually, the write timestamp for a transaction won’t change. But in some situations, it is required to be bumped. Let’s look at these scenarios.</p>
<h3 id="dealing-with-conflicts"><a class="header" href="#dealing-with-conflicts">Dealing with conflicts</a></h3>
<h4 id="read-write-conflict-1"><a class="header" href="#read-write-conflict-1">Read-write conflict</a></h4>
<p>If a write detects that a read has been performed with a greater timestamp, the write will need to advance its timestamp past the read’s timestamp.</p>
<p>The most recent read timestamp for each key is tracked by the database with the Timestamp Oracle (CockroachDB calls it the TimestampCache). This will be covered in another section.</p>
<h4 id="write-write-conflict-1"><a class="header" href="#write-write-conflict-1">Write-write conflict</a></h4>
<p>Write-write conflict happens when a write runs into another write, which could be either committed or uncommitted.</p>
<p>There are two scenarios to look at</p>
<ul>
<li>the write runs into an uncommitted write intent: the write will need to wait for the other transaction to finalize</li>
<li>the write runs into a committed write intent: the transaction performing the write needs to advance its timestamp past the committed write intent’s timestamp.</li>
</ul>
<h4 id="write-read-conflict-1"><a class="header" href="#write-read-conflict-1">Write-read conflict</a></h4>
<p>Write-read happens when a read runs into an uncommitted write. Two scenarios could occur:</p>
<ul>
<li>the uncommitted write intent has a <strong>bigger</strong> timestamp: the read ignores the intent and returns the key with the biggest timestamp less than the read timestamp.</li>
<li>the uncommitted write intent has a <strong>smaller</strong> timestamp: the read needs to wait for the transaction associated with the write intent to be finalized (aborted or committed)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="read-refresh"><a class="header" href="#read-refresh">Read Refresh</a></h1>
<p><em>Read refresh is a technique covered in section 3.4 of <a href="https://www.cockroachlabs.com/guides/thank-you/?pdf=/pdf/cockroachdb-the-resilient-geo-distributed-sql-database-sigmod-2020.pdf">CockroachDB’s research paper</a>.</em></p>
<p>All reads for a transaction are performed at the transaction’s read timestamp. In the last section, we saw that the transaction’s write timestamp can be bumped if it runs into conflicts. Since a transaction commits at the final write timestamp, the read timestamp needs to be advanced when the transaction commits.</p>
<p>However, advancing the read timestamp is not always safe, as in the example below.</p>
<img src="chapter_3/../images/read_refresh.png" width="55%">
<p>In this example, transaction T1 performs a read for key A at timestamp 10. It then performs a write at key B, but it detects a committed write at a higher timestamp, so it advances the timestamp to 16. Finally, it commits. However, this is not safe because it results in a read-write conflict.</p>
<p>When a transaction advances the read timestamp, it must prove that the reads performed at the lower timestamp is still valid at the new timestamp. Suppose the read timestamp is tr and the commit timestamp is tc, the database must prove that the keys read by the transaction have not been updated by another transaction between (tr, tc].</p>
<p>If the database detects that a write has been performed between (tr, tc], the transaction must retry the entire transaction. Otherwise, it is safe to advance its read timestamp to the commit timestamp and commit the transaction. This technique is called read refresh.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hybrid-logical-clock-hlc"><a class="header" href="#hybrid-logical-clock-hlc">Hybrid Logical Clock (HLC)</a></h1>
<p>My original goal was to build a distributed key-value database. I needed a clock that can help me generate unique, increasing MVCC timestamps. After doing some research, I realized that Hybrid Logical Clock (HLC) is what I needed. Even though I ended up just building a single-node key value database, HLC is still useful as it is able to generate unique, incrementing timestamps. </p>
<h3 id="motivation-1"><a class="header" href="#motivation-1">Motivation</a></h3>
<p>Distributed databases need a way to order events and requests. Physical clocks are not reliable as they can go out of sync between servers. Logical clocks can be used to define order across nodes but it does not correlate to physical time. So you cannot perform queries with respect to the physical time.</p>
<p>A hybrid logical clock (HLC) uses a combination of the system timestamp and logical timestamp to have versioned timestamps that can be ordered but still be tied to the physical time.</p>
<h3 id="algorithm"><a class="header" href="#algorithm">Algorithm</a></h3>
<p>The correctness and algorithm for Hybrid Logical Clock are presented <a href="https://cse.buffalo.edu/tech-reports/2014-04.pdf">in this research paper</a>. In this blog, I will focus on the algorithm and not its correctness.</p>
<p>This is the algorithm presented in the paper. Let me explain how it works.</p>
<img src="chapter_3/../images/hlc.png" width="55%">
<p>An HLC’s timestamp has a physical timestamp and a logical timestamp. In this algorithm,</p>
<ul>
<li><code>l.j</code> refers to the biggest physical time the node knows so far.</li>
<li><code>c.j</code> refers to the logical component of the hybrid logical clock, which is used to distinguish two timestamps if their physical component is the same.</li>
<li><code>pt.j</code> refers to the node’s physical time.</li>
</ul>
<p>Each HLC has two methods: send_message and receive_message.</p>
<p><strong>receive_message</strong></p>
<p>This method determines the HLC’s time after receiving a message. The idea is that an HLC keeps track of the latest physical timestamp and logical timestamp known to the node. Each time it receives a message, it updates the latest timestamp if the message’s timestamp is greater than the latest timestamp.</p>
<ul>
<li>First, set the latest physical timestamp (set l.j) to the max of :
<ul>
<li>the current clock’s physical time</li>
<li>the incoming message’s physical time</li>
<li>the previous latest physical timestamp.</li>
</ul>
</li>
<li>Next, determine the logical component of the clock (c.j) as follows:
<ul>
<li>If the incoming message’s physical time is the greatest, set the logical clock to the incoming message’s timestamp’s logical time + 1</li>
<li>If the current clock’s physical timestamp is the greatest, then use 0 as the logical time</li>
<li>If the original latest_timestamp’s physical time is the greatest, then increment the logical component by one</li>
</ul>
</li>
</ul>
<p><strong>send_message</strong></p>
<p>This method determines what timestamp to attach to the message sent to other nodes.</p>
<ul>
<li>if the current physical time is bigger than the latest physical time, then use the current physical time with the logical clock set to 0</li>
<li>Otherwise, increment the latest timestamp’s logical time and use that as the timestamp attached to the message</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="life-of-a-query"><a class="header" href="#life-of-a-query">Life of A Query</a></h1>
<p>For reference, check out <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/docs/tech-notes/life_of_a_query.md">Life of a SQL Query</a> by CockroachDB which outlines the lifecycle of a single query through the different layers of the database.</p>
<p>This page explains the life cycle of a query that interacts with the following entities of the system:</p>
<ul>
<li><strong>Concurrency Manager</strong>: Sequences concurrent, conflicting requests to provide isolation. Once a request is sequenced, it is free to execute as no conflicting requests are running at the same time. The concurrency manager is made up of the latch manager, lock table, and transaction wait queue.</li>
<li><strong>Latch Manager</strong>: Serializes accesses for keys. Only one latch guard can be acquired for a key at any given time.</li>
<li><strong>Lock Table</strong>: Hold locks. Each lock corresponds to an uncommitted write by a transaction. Each lock may have a queue of waiting writes and a queue of waiting reads. The lock outlives the request since a transaction is composed of multiple requests.</li>
<li><strong>Transaction Wait Queue</strong>: Stores the pending transactions for each transaction. This queue is responsible for detecting transaction deadlocks when there is a cycle in the “waits-for” graph</li>
<li><strong>Executor</strong>: Executes the request. This involves reading and writing to the MVCC database built on top of RocksDB</li>
<li><strong>Hybrid Logical Clock</strong>: Generates unique, incrementing timestamps that have a wall clock component and a logical component</li>
</ul>
<p>A <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/request.rs#L57">Request</a> is a unit of execution in the database. Types of requests include start/abort/commit transaction, read, write, etc. The entry point of a request is <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L63">execute_request_with_concurrency_retries</a>, which involves a <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L68">retry loop</a> that attempts to acquire latches/locks and executes the request. If the request runs into write intents, the method handles the write intent and retries.</p>
<h3 id="acquiring-latches-and-locks"><a class="header" href="#acquiring-latches-and-locks">Acquiring latches and locks</a></h3>
<p>Because the database is thread-safe, the database can receive multiple concurrent requests.   <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L70">Sequence_req</a> is called to acquire latches and locks so that the request has full isolation.</p>
<p>Sequence_req first figures out what latches and locks to acquire by calling <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L45">collect_spans</a>. Each request implements a <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/request.rs#L86">collect_spans</a> method that returns the latch/lock keys the request needs to acquire. For example, a <code>WRITE(&quot;A)</code>'s collected keys would be: <code>[&quot;A&quot;]</code>.</p>
<p>Next, the manager <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L49">acquires the latches</a>. If the latch is held by another request, the manager needs to wait until the latch is released because each latch can only be acquired by one request at any time.</p>
<p>The manager then tries to <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L50">acquire locks</a>. If the lock is taken by another transaction, the manager needs to <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L53">wait</a> for the conflicting transaction to finish (or attempt to push the transaction). While it waits, the request needs to release its acquired latches. This is because latches need to be short-lived.</p>
<p>The manager keeps <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L48">looping</a> until all the locks have been acquired. Each time it loops, it reacquires the <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L49">latches</a>.</p>
<p>Once the latch and lock guards are acquired, the executor is ready to execute. At this point, the request has full isolation. Executing read-only requests are slightly different from executing write requests.</p>
<h3 id="executing-read-only-requests"><a class="header" href="#executing-read-only-requests"><strong>Executing read-only requests</strong></a></h3>
<p>As covered in an earlier <a href="https://brianshih1.github.io/little-key-value-db/chapter_3/dealing_with_anomalies.html">page</a>, the database tracks the latest read timestamp performed for every key. This way, when a transaction tries to perform a conflicting write, its write timestamp is advanced to the timestamp after the latest read timestamp.</p>
<p>The database uses the timestamp oracle to track all the reads. Therefore, the executor <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L166">updates the oracle</a> after performing the read.</p>
<h3 id="executing-write-requests"><a class="header" href="#executing-write-requests">Executing write requests</a></h3>
<p>Before performing writes, the request may need to bump its write timestamp to prevent read-write or write-write conflict. Therefore, it <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#LL130C1-L130C1">fetches the latest read timestamp</a> for each key it needs to write from the timestamp oracle. It then <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L145">advances the transaction’s write_timestamp</a> if necessary. After advancing the write timestamp, it can <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L148">execute the request</a>.</p>
<h3 id="performing-the-request"><a class="header" href="#performing-the-request">Performing the Request</a></h3>
<p>Each request implements the <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/request.rs#L94">execute</a> method which interacts with the storage layer. The storage layer of the database is built on top of RocksDB. As an example, the PutRequest’s execute implementation <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/request.rs#L385">puts the MVCC key-value record into the storage layer</a>. We will cover the <code>execute</code> method for each request type in more detail later.</p>
<p>Finally, the executor <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/execute/executor.rs#L85">finishes the request</a> - <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L76">releasing the latch guards</a> and <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/concurrency/concurrency_manager.rs#L77">dequeuing the lock guards</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="mvcc-1"><a class="header" href="#mvcc-1">MVCC</a></h1>
<p>Earlier, we covered how MVCC works <a href="https://brianshih1.github.io/little-key-value-db/chapter_3/mvcc.html">here</a>. In this section, we will talk about how the MVCC layer is implemented.</p>
<p>In my MVCC database, HLC (hybrid logical clock) timestamps are used to distinguish different versions of the same key. A key with a timestamp is called an <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_key.rs#L7">MVCCKey</a>. </p>
<p>An MVCCKey is a combination of a Timestamp and a Key:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MVCCKey {
    pub key: Key,
    pub timestamp: Timestamp,
}
<span class="boring">}</span></code></pre></pre>
<p>The timestamp’s structure is:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Timestamp {
    pub wall_time: u64,
    pub logical_time: u32,
}
<span class="boring">}</span></code></pre></pre>
<p>The Key’s type is</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub type Key = Vec&lt;u8&gt;;
<span class="boring">}</span></code></pre></pre>
<p>The database uses RocksDB as the storage engine. We need to encode the MVCCKey into a RocksDB key. Inspired by CockroachDB <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc_key.go#L161">EncodeMVCCKey method</a>, the MVCCKey is encoded into the following form:</p>
<p><code>[key] [wall_time] [logical_time]</code></p>
<p>Here is the implementation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn encode_mvcc_key(mvcc_key: &amp;MVCCKey) -&gt; Vec&lt;u8&gt; {
    let mut key_vec = mvcc_key.key.to_vec();
    let timestamp_vec = encode_timestamp(mvcc_key.timestamp);
    key_vec.extend(timestamp_vec);
    key_vec
}

pub fn encode_timestamp(timestamp: Timestamp) -&gt; Vec&lt;u8&gt; {
    let mut wall_time_bytes = timestamp.wall_time.to_le_bytes().to_vec();
    let logical_time_bytes = timestamp.logical_time.to_le_bytes().to_vec();
    wall_time_bytes.extend(logical_time_bytes);
    wall_time_bytes
}
<span class="boring">}</span></code></pre></pre>
<p>Earlier, we covered that a write intent is stored to represent uncommitted writes. A key can only have one write intent at a time. We use the MVCCKey with the zero timestamp: Timestamp { wall_time: 0, logical_time: 0 } to represent the key for a write intent.</p>
<p>When users query for a key, the database returns the latest version of that key. To make this faster, MVCCKeys are sorted from highest timestamp to the lowest timestamp in the storage engine, with the exception of the zero timestamp which is stored before all other versions of the same key.</p>
<p>This is only possible because RocksDB allows developers to customize the order of keys in the table through <a href="https://docs.rs/rocksdb/latest/rocksdb/struct.Options.html#method.set_comparator">set_comparator</a>. <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/storage.rs#L50">Here</a> is my implementation of the custom comparator. The comparator gives the highest precedence to the zero timestamp for the same key. Otherwise, it uses the key and the timestamp to order the MVCC keys.</p>
<h2 id="core-apis"><a class="header" href="#core-apis">Core APIs</a></h2>
<p>The core API of the MVCC layer includes:</p>
<ul>
<li>MVCC_SCAN</li>
<li>MVCC_GET</li>
<li>MVCC_PUT</li>
</ul>
<p>Most interactions with RocksDB are performed with this set of APIs, which are just abstractions over RocksDB’s methods and iterators.</p>
<h3 id="mvcc_scan"><a class="header" href="#mvcc_scan">MVCC_SCAN</a></h3>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L99">MVCC_SCAN</a> takes a start key, an end key, and a timestamp as inputs. MVCC_SCAN returns an array of results that contains the keys in the range [start_key, end_key). Only keys with a timestamp less than or equal to the input timestamp is added to the scan results. MVCC_SCAN also collects any write intents that it found along the way.</p>
<p><strong>Algorithm</strong></p>
<ul>
<li>It first creates an <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_iterator.rs#L24">MVCCIterator</a>, which is a wrapper around RocksDB’s iterator</li>
<li>It then creates an <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L107">MVCCScanner</a> with the iterator and performs <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L115">scan</a></li>
<li>The idea behind scan is to first a<a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L65">dvance the iterator to the intent key of the start key</a>. Write intents have higher precedence than other MVCC keys, so it’s guaranteed that the iterator didn’t skip any keys that may be in the output</li>
<li>it then keeps <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L88">advancing the iterator</a> with a <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L66">loop</a> until the iterator’s current key <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L76">exceeds the end key</a></li>
<li>during each iteration, the scanner checks if the record’s key is an intent key. <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L107">If it is,</a> add it to found_intents. Otherwise, if the MVCC key’s timestamp is ≤ the input timestamp, <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L145">add it to the results</a> and advance to the next key. However, if the key’s timestamp is greater than the input timestamp, it must <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc_scanner.rs#L150">seek an older version of the key</a></li>
</ul>
<p><strong>CockroachDB’s MVCCScan</strong></p>
<p>For reference, here is CockroachDB’s implementation of <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#L3995">MVCCScan</a>. The core idea is similar. It initializes an <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#LL3739C31-L3739C42">mvccScanner</a>, <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/pebble_mvcc_scanner.go#L655">seeks to the start of the scan</a>, and <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/pebble_mvcc_scanner.go#L658">keeps looping</a> until it exceeds the range. </p>
<p>On each iteration, it checks if the key is an intent key <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/storage/pebble_mvcc_scanner.go#L723">by checking if it’s empty</a>. It then checks if the MVCC key’s timestamp is <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/storage/pebble_mvcc_scanner.go#L745">equal to the input timestamp</a>, <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/storage/pebble_mvcc_scanner.go#L786">greater than the input timestamp</a>, or less than the input timestamp, in that case it <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/storage/pebble_mvcc_scanner.go#L829">seeks an older version of the key</a>.</p>
<h3 id="mvcc_get"><a class="header" href="#mvcc_get">MVCC_GET</a></h3>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L63">MVCC_GET</a> takes a key, a timestamp, and an optional transaction as inputs. It returns the most recent value for the specified key whose timestamp is less than or equal to the supplied timestamp. If it runs into an uncommitted value, it returns a WriteIntentError.</p>
<p><strong>Algorithm</strong></p>
<ul>
<li>MVCC_GET is implemented as an MVCC_SCAN where a single key is retrieved. This is achieved by <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L78">setting both the start key and the end key to the same key</a>.</li>
</ul>
<p><strong>CockroachDB’s MVCCGet</strong></p>
<p>For reference, <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L63">here</a> is CockroachDB’s implementation of MVCCGet. The idea to use MVCCScanner is inspired by them. In their implementation, they implement mvcc_get a<a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L73">s a scan with start_key = end_key</a>.</p>
<h3 id="mvcc_put"><a class="header" href="#mvcc_put">MVCC_PUT</a></h3>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L122">MVCC_PUT</a> takes a key, a timestamp, and an optional transaction and tries to insert a timestamped record into the MVCC database. If a transaction is provided, a write intent is placed in the database. Otherwise, the raw value is placed into the database.</p>
<p>Before writing, MVCC_PUT must verify that there are no uncommitted intent for the same key. This is because there can only be a write intent for a key. If an uncommitted intent already exists for the same key, an error is returned. </p>
<p><strong>Algorithm:</strong></p>
<ul>
<li>
<p>first, it tries to <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L151">fetch the intent record</a></p>
</li>
<li>
<p>if an intent is found, there are 2 scenarios</p>
<ul>
<li><a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L158">the intent’s transaction is the same transaction as the current transaction</a>. In this case, we’re overwriting our own transaction which is acceptable - we don’t do anything</li>
<li>Otherwise, we check the status of the transaction record that corresponds to the write intent. If the transaction is pending, <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L162">a WriteIntentError is returned</a></li>
</ul>
</li>
<li>
<p>After verifying that there are no uncommitted intent for the same key, we are free to insert into the database. </p>
</li>
<li>
<p>If a transaction is provided, <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L193">an uncommitted intent is placed into the database</a>. An UncommittedValue contains the value, the transaction ID and the write_timestamp of the transaction at the time of insertion.</p>
</li>
<li>
<p>Otherwise, <a href="https://github.com/brianshih1/little-key-value-db/blob/194d3f9e65bb69d674f0217f2a02b18ace12ee7e/src/storage/mvcc.rs#L206">the raw value is placed into the database</a>.</p>
</li>
</ul>
<p><strong>CockroachDB’s MVCCPut</strong></p>
<p>For reference, here is CockroachDB’s implementation of <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#L1442">MVCCPut</a>. The core idea is the same. It <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#L1859">checks if an intent was found</a>. If there is an uncommitted write intent whose transaction ID is not the same as the MVCCPut’s transaction’s ID, <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#L1863">a WriteIntentError is returned</a>. </p>
<p>Otherwise if the intent’s timestamp is less than the write timestamp, clear <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#L2024">it</a> so that MVCCPut can overwrite it. Finally, MVCCPut <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/storage/mvcc.go#L2195">writes the mvcc value</a>.</p>
<p>[]: </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="latch-manager"><a class="header" href="#latch-manager">Latch Manager</a></h1>
<h3 id="latch-manager-api"><a class="header" href="#latch-manager-api">Latch Manager API</a></h3>
<p>Latch Manager’s job is to serialize access to keys. Latch Manager’s API is composed of two methods: Acquire and Release</p>
<p><strong>Acquire: (keys) → LatchGuard</strong></p>
<p>Acquire takes a set of keys and returns a latch guard. Once the latch guard is obtained, any other calls to Acquire will have to wait until the latch guard is released. In other words, a thread has isolation for the keys after calling Acquire.</p>
<p><strong>Release: (LatchGuard) → ()</strong></p>
<p>Release releases the latch guard, allowing other requests to acquire the latches.</p>
<h3 id="building-a-thread-safe-b-tree"><a class="header" href="#building-a-thread-safe-b-tree">Building a Thread-safe B+ Tree</a></h3>
<p>The Latch Manager is implemented with a thread-safe B+ Tree. Before talking about how the Latch Manager is implemented with a B+ tree, let’s first talk about how the concurrent tree is implemented.</p>
<p>If you’re not interested in learning how the concurrent B+ tree is implemented, scroll down to the section <code>Using the Thread-Safe B+ Tree to implement Latch Manager</code>.</p>
<p>There are plenty of online materials about what B+ trees are so I won’t go into too much detail. In summary, the B+ tree is a self-balancing m-ary tree. A B+ tree is made up of root, internal nodes, and leaf nodes.</p>
<p>B+ tree has a few invariants. For example, every internal node has at least floor(m/2) children, all leaves are at the same distance from the root, etc. To maintain these invariants, nodes may split into multiple nodes, steal from siblings nodes, or merge with sibling/parent nodes during insertion and deletion.</p>
<p>When implementing the B+ tree, I relied heavily on this <a href="https://dichchankinh.com/~galles/visualization/BPlusTree.html">B+ visualization tool</a>. The visualization tool provides step-by-step visualizations for B+ tree algorithms. For example, here are the steps for a <code>Delete</code> operation.</p>
<img src="chapter_5/../images/b_plus_tree_deletion.png" width="75%">
<h3 id="latch-crabbingcoupling"><a class="header" href="#latch-crabbingcoupling">Latch Crabbing/Coupling</a></h3>
<p>What makes a thread-safe B+ tree different from normal B+ is that a thread-safe B+ tree can be accessed by multiple threads concurrently. If not designed correctly, threads can crash or yield incorrect results if they try to modify the same set of nodes concurrently.</p>
<p>This is where Latch Crabbing (or coupling) comes in. Latch crabbing is a protocol to allow multiple threads to access and modify the B+ tree concurrently. This is covered in CMU’s lecture (check out their <a href="https://15445.courses.cs.cmu.edu/fall2022/slides/09-indexconcurrency.pdf">lecture slide</a> and <a href="https://www.youtube.com/watch?v=5KClozM1jjw&amp;list=PLSE8ODhjZXjaKScG3l0nuOiDTTqpfnWFf&amp;index=9&amp;ab_channel=CMUDatabaseGroup">video</a>).</p>
<p>Latches are lightweight synchronization objects that protect a data structure from concurrent access. If a read latch for a node, no other threads can perform mutation to that node. If a write latch is held for a node, no other threads can read or write that node.</p>
<p>The idea behind latch crabbing is that when traversing the B+ tree, the thread would get a latch on the parent (starting from the root) before getting a latch on the child node. Then the latch for the parent node is released only if it is safe to do so. It is safe to release the latch for the parent node if it will not split or merge when modified. Whether a node is safe depends on what kind of operation the thread is executing:</p>
<ul>
<li><code>Deletion</code>: a node is safe when it is more than half-full (otherwise it will merge with another node when a key is deleted).</li>
<li><code>Insert</code>: a node is safe when it is not full (otherwise it will split when a key is inserted).</li>
</ul>
<p>In my B+ tree implementation, latches are implemented with <code>RwLock</code>s. Each node is wrapped around a <code>RwLock</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub type LatchNode&lt;K&gt; = Arc&lt;RwLock&lt;Node&lt;K&gt;&gt;&gt;;

pub enum Node&lt;K: NodeKey&gt; {
    Internal(InternalNode&lt;K&gt;),
    Leaf(LeafNode&lt;K&gt;),
}
<span class="boring">}</span></code></pre></pre>
<p>Furthermore, each property inside the InternalNode and LeafNode are also wrapped around RwLock to provide interior mutability.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct InternalNode&lt;K: NodeKey&gt; {
    pub keys: RwLock&lt;Vec&lt;K&gt;&gt;,
    // a key's corresponding left edge will contain nodes with keys stricly less
    // than the key
    pub edges: RwLock&lt;Vec&lt;NodeLink&lt;K&gt;&gt;&gt;,
    pub order: u16,
}

pub struct LeafNode&lt;K: NodeKey&gt; {
    pub keys: RwLock&lt;Vec&lt;K&gt;&gt;,
    pub left_ptr: WeakNodeLink&lt;K&gt;,
    pub right_ptr: WeakNodeLink&lt;K&gt;,
    pub order: u16,
    pub waiters: RwLock&lt;Vec&lt;RwLock&lt;LatchWaiters&gt;&gt;&gt;,
}

pub type NodeLink&lt;K&gt; = RwLock&lt;Option&lt;LatchNode&lt;K&gt;&gt;&gt;;
pub type WeakNodeLink&lt;K&gt; = RwLock&lt;Option&lt;Weak&lt;RwLock&lt;Node&lt;K&gt;&gt;&gt;&gt;&gt;;
<span class="boring">}</span></code></pre></pre>
<p>To be honest, I struggled quite a bit implementing the concurrent B+ tree. This was my first time learning Rust and I had to wrestle with the compiler multiple times. One thing I struggled with when implementing <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/latch_manager/latch_interval_btree.rs#L985">insert</a> and <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/latch_manager/latch_interval_btree.rs#L1117">delete</a> was finding a way to store the latches.</p>
<p>I originally tried to keep a stack of <code>RwLockWriteGuard</code> as I traversed the tree. But Rust doesn’t compile because the guard at <code>stack[n]</code> references the Arc from <code>stack[n-1]</code>. In Rust, the value and the reference to that value cannot belong to the same struct. It took me a while to realize that taking a recursive approach when implementing tree algorithms in Rust is easier - the recursion creates a stack for us in the form of the call stack.</p>
<p>Going back to latch coupling, this is how we <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/latch_manager/latch_interval_btree.rs#L914">compute whether a node is safe or not</a> during insertion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let is_safe = child_node_size &lt; usize::from(self.order - 1);
<span class="boring">}</span></code></pre></pre>
<p>We make sure that the child isn’t at capacity yet so won’t split if a key is inserted.</p>
<p>This is how we <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/latch_manager/latch_interval_btree.rs#L1058">compute whether a node is safe or not</a> during deletion.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let is_safe = child_has_spare_key
	&amp; !is_edge_key_the_delete_key &amp;&amp; is_ancestor_safe;
<span class="boring">}</span></code></pre></pre>
<p>We make sure that the child is at least half full (has spare key) so that it won’t merge with the parent node if a key is deleted.</p>
<p>To clarify, the latches here aren’t the same latches we refer to when we talk about the latch that is acquired through the <code>Acquire</code> method in the Latch Manager. The latches here are used to protect the B+ tree data structure. The latches acquired by a latch manager functions more as a lock.</p>
<h3 id="writing-unit-tests"><a class="header" href="#writing-unit-tests">Writing Unit Tests</a></h3>
<p>When writing unit tests for tree algorithms, I like to write declarative tests. Instead of having to imperatively build a B+ tree to a starting state, I used a test data structure that can be used to generate a B+ tree. For example, here is the code to create a tree.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let test_node = TestNode::Internal(TestInternalNode {
    keys: Vec::from([10]),
    edges: Vec::from([
        Some(TestNode::Leaf(TestLeafNode {
            keys: Vec::from([5]),
        })),
        Some(TestNode::Leaf(TestLeafNode {
            keys: Vec::from([10, 20]),
        })),
    ]),
});
let tree = create_test_tree(&amp;test_node, 3);
<span class="boring">}</span></code></pre></pre>
<p>After performing the mutation algorithms, I then asserted the resulting B+ tree as follows</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>tree.insert(Range {
    start_key: 15,
    end_key: 15,
});
let test_node = TestNode::Internal(TestInternalNode {
    keys: Vec::from([10, 15]),
    edges: Vec::from([
        Some(TestNode::Leaf(TestLeafNode {
            keys: Vec::from([5]),
        })),
        Some(TestNode::Leaf(TestLeafNode {
            keys: Vec::from([10]),
        })),
        Some(TestNode::Leaf(TestLeafNode {
            keys: Vec::from([15, 20]),
        })),
    ]),
});
assert_tree(&amp;tree, &amp;test_node);
<span class="boring">}</span></code></pre></pre>
<p>Feel free to check out the <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/latch_manager/latch_interval_btree_test.rs">unit tests</a> I wrote for the my concurrent B+ tree implementation!</p>
<h3 id="using-the-thread-safe-b-tree-to-implement-latch-manager"><a class="header" href="#using-the-thread-safe-b-tree-to-implement-latch-manager">Using the Thread-Safe B+ Tree to implement Latch Manager</a></h3>
<p>So far, we’ve mostly talked about how to implement the concurrent B+ tree. Now, let’s talk about how the B+ tree is actually used to implement the Latch Manager API.</p>
<p><strong>Acquire</strong></p>
<p>As a refresher, Acquire takes a set of keys and returns a Latch Guard. Once a latch guard is acquired by a thread, other threads would have to wait until the latch guard is released.</p>
<p>Based on this requirement, there are a few mechanisms we need to design for:</p>
<ul>
<li>a thread calling Acquire needs to be able to detect that the latches are currently owned by another thread.</li>
<li>a thread calling Acquire that is waiting for another thread to release its latches needs to be able to detect when the latch guards are released</li>
</ul>
<p>Each key inside the B+ tree’s leaf nodes represents an acquired latch. A thread can detect that a latch for a key is acquired by checking if the key exists in the B+ tree.</p>
<p>When a latch is released, the database uses message passing to notify the waiting thread that it can stop waiting.</p>
<p>The B+ tree’s insert API is <code>insert: (key) → LatchKeyGuard</code>.</p>
<p>LatchKeyGuard is an enum:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum LatchKeyGuard {
    Acquired,
    NotAcquired(LatchGuardWait),
}

pub struct LatchGuardWait {
    pub receiver: Receiver&lt;()&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>During Acquire, the thread would first try to insert the key into the B+ tree. If the key doesn’t exist in the B+ tree yet, the key is inserted and <code>LatchKeyGuard::Acquired</code> is returned. Otherwise, a channel is created and the sender is queued onto the latch. The function then returns <code>LatchKeyGuard::NotAcquire</code> along with the receiver. The thread can then wait for the receiver to receive a message that the latch has been released. <a href="https://github.com/brianshih1/little-key-value-db/blob/master/src/latch_manager/latch_manager.rs#L46">Here</a> is the code for that.</p>
<p>Each key in the <code>LeafNode</code> contains a corresponding <code>LatchWaiters</code>. Each LatchWaiters contain the array of senders, each has a corresponding <code>receiver</code> returned by the <code>Insert</code> method.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct LeafNode&lt;K: NodeKey&gt; {
    pub keys: RwLock&lt;Vec&lt;K&gt;&gt;,
		...
    pub waiters: RwLock&lt;Vec&lt;RwLock&lt;LatchWaiters&gt;&gt;&gt;,
}

pub struct LatchWaiters {
    pub senders: Vec&lt;Mutex&lt;Sender&lt;()&gt;&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Each key in the <code>LeafNode</code> contains a corresponding <code>LatchWaiters</code>. Each LatchWaiters contain an array of senders, which are requests waiting for the latch guard to be released.</p>
<p>Deadlock is possible with this approach. For example, suppose both <code>request 1</code> and <code>request 2</code> want to Acquire latches for the keys <code>A</code> and <code>B</code>. If <code>request 1</code> acquires key A first and <code>request 2</code> acquires key B first, then a deadlock has occurred since the two requests are blocking each other.</p>
<p>To deal with the deadlock, we use a timeout approach. <code>Acquire</code> would release all guards and retry <a href="https://github.com/brianshih1/little-key-value-db/blob/master/src/latch_manager/latch_manager.rs#L51">if the timer times out</a>. There are likely better ways to deal with deadlocks but this was good enough for a MVP.</p>
<p><strong>Release</strong></p>
<p>Release is fairly simple. All it does is that it <a href="https://github.com/brianshih1/little-key-value-db/blob/master/src/latch_manager/latch_manager.rs#L84">iterates through the latches that it acquired and deletes it from the B+ tree</a>. The B+ tree would then notify the waiters that the latch is released.</p>
<h3 id="terminologies"><a class="header" href="#terminologies">Terminologies</a></h3>
<p>You are probably wondering - the “latches” acquired by the latch manager sounds more like a lock. In fact, if we look at this <a href="https://15445.courses.cs.cmu.edu/fall2022/slides/09-indexconcurrency.pdf">slide</a> from CMU’s lecture, we can see that latches are supposed to be short-lived and don’t rely on mechanisms such as Waits-for, Timeout, etc.</p>
<img src="chapter_5/../images/locks_vs_latches.png" width="65%">
<p>To clarify, the RwLock protecting the internal nodes of the B+ tree function as latches. The leaf nodes that contain a queue of waiters act more like a lock (though not a transaction lock).</p>
<h3 id="cockroachdbs-latch-manager"><a class="header" href="#cockroachdbs-latch-manager"><strong>CockroachDB’s Latch Manager</strong></a></h3>
<p>For reference, <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_control.go#L489">this</a> is CockroachDB’s API for latch manager. My Latch Manager’s API is inspired by CockroachDB’s Latch Manager API but my implementation is different. In <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_control.go#L489">this doc</a>, CockroachDB outlines the evolution of their latch manager implementation.</p>
<p>CockroachDB uses an interval tree of RWMutexes. <a href="https://github.com/cockroachdb/cockroach/commit/c855b45b539d8870a8d3f9f0711c900b95e0d36c">This CockroachDB PR</a> introduces a BTree implementation based on immutable data structures with copy-on-write mechanisms. I wasn’t able to fully understand how it works but I might revisit and build another implementation for my Latch Manager in the future!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lock-table"><a class="header" href="#lock-table">Lock Table</a></h1>
<img src="chapter_5/../images/lock_table.png" width="75%">
<p>The lock table maintains a set of locks that are held by pending transactions. Each lock in the table contains a wait-queue, where conflicting transactions can queue onto and wait until the lock has been released. In contrast to latches, which exist only for the duration of a request, locks are held for the lifetime of a transaction which may span multiple requests.</p>
<p>As we noted before, each key can only have one uncommitted intent at a time. The lock table guarantees this invariant by ensuring that conflicting transactions are queued while an uncommitted intent is unresolved.</p>
<h3 id="lock-table-api"><a class="header" href="#lock-table-api">Lock Table API</a></h3>
<p><strong>Scan_and_enqueue: (request, txn) → (bool, LockTableGuard)</strong></p>
<p>This method loops over the keys that the request will access. If it finds a lock for one of the keys, it enqueues the request onto the lock and terminates - returning true and a lock table guard. Returning true here means that the thread needs to wait until the lock is released. Returning false here means that no conflicting locks are detected, and the request is free to perform the writes.</p>
<p>It’s important to note that the latches for the corresponding keys must be held when calling this function.</p>
<p><strong>Wait_for: (lock_table_guard) → Result&lt;(), Error&gt;</strong></p>
<p>This method takes a lock guard and waits until the queued request is at the front of the wait queue. This means that the request is safe to re-acquire latches and rescan the lock table to find any other conflicting locks. This method is also responsible for pushing the transaction if it times out, which may be due to deadlocks.</p>
<p>It’s important to note that this method must be called after latches are dropped.</p>
<p><strong>Add_discovered_lock: (lock_table_guard, txn_intent) → ()</strong></p>
<p>This method is called when an uncommitted intent is discovered during a read or write. It adds the lock guard of the request that found the intent to the wait queue.</p>
<p><strong>Acquire_lock: (key, txn) → ()</strong></p>
<p>This method is called after a write intent is created. It informs the lock table that a new lock has been acquired and other requests need to wait until the lock is released.</p>
<p>It’s important to note that the latch for the key must be held when this method is called.</p>
<p><strong>Dequeue: (lock_table_guard) → ()</strong></p>
<p>This method removes the request from the lock’s wait queues. Note that this method doesn’t release the lock. The only way to release the lock is when the transaction aborts or commits, which resolves the write intent.</p>
<p>Note that latches may or may not be held for this method to be called.</p>
<p><strong>Update_locks: (key, update_lock) → ()</strong></p>
<p>This method updates the lock table when the lock is updated or released, which happens when the transaction has been committed or aborted. This function frees all the queued readers and the first queued writer.</p>
<h3 id="lock-state"><a class="header" href="#lock-state">Lock State</a></h3>
<p>Conceptually, Lock Table is just a map from keys to lock states.</p>
<p>Each Lock State contains the queued readers and writers for the lock. This is the struct:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct LockState {
    pub lock_holder: Arc&lt;RwLock&lt;Option&lt;TxnMetadata&gt;&gt;&gt;,

    pub reservation: Arc&lt;RwLock&lt;Option&lt;LockTableGuardLink&gt;&gt;&gt;,

    pub queued_writers: Arc&lt;RwLock&lt;Vec&lt;LockTableGuardLink&gt;&gt;&gt;,

    pub waiting_readers: Arc&lt;RwLock&lt;Vec&lt;LockTableGuardLink&gt;&gt;&gt;,

    pub last_committed_timestamp: RwLock&lt;Option&lt;Timestamp&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The lock holder represents whether the lock is held by a transaction. If there is a lock holder, then there is an unresolved uncommitted intent.</p>
<p>Even when the lock_holder is <code>None</code>, which means that the uncommitted intent has been resolved, the lock state may not be cleaned up. This is because there may be pending requests that may add uncommitted intents.</p>
<p>Pending requests take the form of a lock table guard. These requests need to wait for their turn. Read-only requests are placed inside the <code>waiting_readers</code> and write requests are placed inside <code>queued_writers</code>.</p>
<p>When the uncommitted intent has been resolved, all <code>waiting_readers</code> may be released. The reason that all readers can be released is that readers only need to wait if the uncommitted write intent has a smaller timestamp to prevent read-write conflicts. If the read request is able to acquire the latches and perform the read, the next uncommitted write intent will have a greater timestamp since it will consult the timestamp oracle.</p>
<p>On the other hand, only one <code>queued_writers</code> is released. This is because there can only be one uncommitted write intent at a time, so releasing all the writers at once will likely result in conflicts again. When a queued writer is released, it is appointed to be the <code>reservation</code>. <code>Reservation</code> denotes that a write request is in progress and will create an uncommitted intent.</p>
<p>There are a few invariants for the lock state:</p>
<ul>
<li>a lock_holder and a reservation cannot exist at the same time</li>
<li>if the lock_holder is <code>None</code>, then <code>waiting_readers</code> must be empty</li>
</ul>
<p>Each lock table guard is 1-1 with a pending request. It’s an abstraction over a channel. A lock table guard has a corresponding receiver and a sender. The sender sends a message when the lock guard has been released. The receiver detects that the lock guard has been released and proceeds with the request.</p>
<h3 id="implementing-the-lock-table-api"><a class="header" href="#implementing-the-lock-table-api">Implementing the Lock Table API</a></h3>
<p>Now that we know the data structure of the lock table, let’s revisit the API and briefly talk about how each method is implemented.</p>
<p><strong>Scan_and_enqueue: (request, txn) → (bool, LockTableGuard)</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L199">This method</a> <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L215">loops through the request’s keys</a>. If a lock state exists for the key, it checks if it needs to wait for the lock state. Here are the rules determining whether a request needs to wait:</p>
<ul>
<li>if a lock holder exists
<ul>
<li>if the request is read-only, then it only needs to wait <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L617">if the uncommitted intent’s timestamp is less than the read’s timestamp</a></li>
<li>if the request <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L605">belongs to the same transaction</a> as the lock holder, it doesn’t need to wait.</li>
</ul>
</li>
<li>if a lock holder doesn’t exist
<ul>
<li>if the request is read-only, it doesn’t have to wait</li>
<li>If the lock state doesn’t have a reservation, the lock guard <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L599">claims the reservation</a> and doesn’t need to wait.</li>
<li>if the reservation and the request <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L595">belong to the same transaction</a>, then it doesn’t need to wait.</li>
</ul>
</li>
</ul>
<p>If a request needs to wait, then it queues itself onto the <code>queud_writers</code> and <code>waiting_readers</code>.</p>
<p>Scan_and_enqueue returns true if it doesn’t have to wait for all the keys. Otherwise, it terminates early by returning false with a created lock guard.</p>
<p><strong>Wait_for: (lock_table_guard) → Result&lt;(), Error&gt;</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L245">This method</a> simply uses the lock state guard’s receiver to <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L262">wait until the lock guard has been released</a>. In the case of a deadlock, it <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L266">detects the deadlock with a timer</a>. In that case, it tries to <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L276">push the transaction</a>. This will be covered later.</p>
<p><strong>Add_discovered_lock: (lock_table_guard, txn_intent) → ()</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L143">This method</a> inserts a lock state into the lock table if one didn’t exist yet. It <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L163">claims the lock holder</a>. If the request that detected the uncommitted intent is a reader, it pushes itself onto the <code>waiting_readers</code>. Otherwise, it pushes itself onto the <code>queued_writers</code>.</p>
<p><strong>Acquire_lock: (key, txn) → ()</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L320">This method</a> <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L349">updates the lock holder</a> of the lock state. If <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L342">a reservation exists</a> or if a <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L337">lock holder with a different transaction ID exists</a>, then there is an error.</p>
<p><strong>Dequeue: (lock_table_guard) → ()</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L305">This method</a> removes itself as a reservation <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L650">if it was the reserver</a>. Otherwise, it <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L657">removes itself</a> from the <code>queued_writers</code> and <code>waiting_readers</code>.</p>
<p><strong>Update_locks: (key, update_lock) → ()</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L374">This method</a> <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L421">sets the lock_holder to <code>None</code></a>. It then calls <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L463">lock_is_free</a>, which <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L502">clears</a> all <code>waiting_readers</code> and lets the first queued_writer <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L510">claim itself as the reservation</a>.</p>
<h3 id="cockroachdbs-implementation"><a class="header" href="#cockroachdbs-implementation">CockroachDB’s Implementation</a></h3>
<p>My Lock Table API is very similar to CockroachDB’s <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/concurrency/concurrency_control.go#L580">Lock Table API</a>, which consists of the same methods such as <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/concurrency/concurrency_control.go#L591">ScanAndEnqueue</a>, <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/concurrency/concurrency_control.go#L609">Dequeue</a>, <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/concurrency/concurrency_control.go#L609">AddDiscoveredLock</a>, <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/concurrency/concurrency_control.go#L669">AcquireLock</a>, etc. </p>
<p>Unlike my LockTable which uses a simple <code>HashMap</code>, CockroachDB’s lock state is <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/concurrency/lock_table.go#L236">stored in a btree</a>. Other than that, the algorithms are quite similar.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="timestamp-oracle"><a class="header" href="#timestamp-oracle">Timestamp Oracle</a></h1>
<p>As mentioned earlier, when a transaction performs a write on a key, its write timestamp must be greater than any read timestamps performed on the same key to prevent read-write conflicts. Therefore, the database needs to track the maximum timestamp that key ranges were read from. That is the job of the timestamp oracle. Timestamp Oracle is a data structure that stores the maximum timestamp that key ranges were read from.</p>
<p>Timestamp oracle is introduced in Yabandeh’s research paper, <a href="https://dl.acm.org/doi/10.1145/2168836.2168853">A Critique of Snapshot Isolation</a>. In the paper, Yabandeh proves that read-write conflict avoidance is sufficient for serializability. For a more detailed explanation of the timestamp oracle, check out this CockroachDB blog and scroll down to the section <code>Read-Write Conflicts – Read Timestamp Cache</code>.</p>
<h3 id="timestamp-oracle-api"><a class="header" href="#timestamp-oracle-api">Timestamp Oracle API</a></h3>
<p>The Timestamp Oracle’s API consists of two methods: get_max_timestamp and add</p>
<p><strong>Get_max_timestamp: (start_key, end_key) → Timestamp</strong></p>
<p>The method returns the max timestamp, which overlaps the interval [start_key, end_key].</p>
<p><strong>Add: (timestamp, start_key, end_key) → ()</strong></p>
<p>The method adds the timestamp for the range [start_key, end_key] to the oracle.</p>
<h3 id="red-black-tree"><a class="header" href="#red-black-tree"><strong>Red-Black Tree</strong></a></h3>
<p>The timestamp oracle is implemented with a red-black interval tree. There are plenty of materials online on how to implement a red-black tree, so I won’t go into the details. In summary, a red-black tree is a self-balancing binary search tree in which each node is marked as either black or red. The red-black tree has some invariants around the red and black nodes. The start key of the interval is used to order keys in the red-black tree.</p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/llrb/llrb.rs">Here</a> is my implementation of the red-black tree.</p>
<h3 id="implementing-the-timestamp-oracle-api"><a class="header" href="#implementing-the-timestamp-oracle-api">Implementing the Timestamp Oracle API</a></h3>
<p><strong>Add</strong></p>
<p><a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/timestamp_oracle/oracle.rs#L61">Add</a>’s implementation is really simple. It just inserts the interval into the red-black tree.</p>
<p><strong>Get_max_timestamp</strong></p>
<p>First, the function collects all overlap nodes. This is efficient because the timestamp oracle is a Binary Search Tree. Next, the function finds the max timestamp amongst the nodes and returns it.</p>
<h3 id="cockroachdbs-implementation-1"><a class="header" href="#cockroachdbs-implementation-1">CockroachDB’s Implementation</a></h3>
<p>CockroachDB calls the timestamp oracle their timestamp cache. CockroachDB’s interface for the timestamp cache is <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/tscache/cache.go#L53">here</a>. They have two implementations for the cache: <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/util/interval/llrb_based_interval.go">red-black tree based</a> and <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/util/interval/btree_based_interval.go">BTree based</a>.</p>
<p>CockroachDB’s cache is bounded. It evicts keys if the cache exceeds a certain size It also maintains a “low watermark” that is used whenever GetMax is called but the interval isn’t in the cache. To decide which keys to exceeding, CockroachDB <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/util/cache/cache.go#L114">holds a double-linked list of Entry elements</a>. The order of entries is based on the <a href="https://github.com/cockroachdb/cockroach/blob/master/pkg/util/cache/cache.go#L31">eviction policy</a>, one of which is LRU and another is FIFO. I didn’t bother to implement this in my MVP.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deadlock-detection"><a class="header" href="#deadlock-detection">Deadlock Detection</a></h1>
<p>Deadlocks can happen if two conflicting transactions are waiting for each other to finish.</p>
<img src="chapter_5/../images/deadlock.png" width="65%">
<p>In the example above, T1 performs a write at A then T2 performs a write at B. Then T1 tries to perform a write at B, but the request gets queued to the lock table as T2 holds the lock at B. On the other hand, T2 tries to perform a write at A, but the request gets queued to the lock table as TA holds the lock at A.</p>
<p>At this point, the lock table looks like this:</p>
<img src="chapter_5/../images/deadlock_lock_table.png" width="75%">
<p>This is a deadlock as neither transaction can proceed as they are waiting for the other transactions to resolve.</p>
<p>To deal with situations like this, CockroachDB introduced <a href="https://www.cockroachlabs.com/docs/stable/architecture/transaction-layer.html#txnwaitqueue">TxnWaitQueue</a>, a data structure that can detect deadlocks.</p>
<h3 id="txnwaitqueue"><a class="header" href="#txnwaitqueue">TxnWaitQueue</a></h3>
<p>TxnWaitQueue is a map from blocking transactions to blocked transactions. We call a blocked transaction a <code>pusher</code> and call a blocking transaction a <code>pushee</code>. In other words, TxnWaitQueue is a map from <code>pushee</code>s to a list of <code>pusher</code>s.</p>
<p>If we have a three-way deadlock, TxnWaitQueue may look something like this:</p>
<pre><code>txn1 -&gt; [txn2]
txn2 -&gt; [txn3]
txn3 -&gt; [tx1]
</code></pre>
<p>Each pusher is wrapped around a data structure called <code>WaitingPush</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct WaitingPush {
    dependents: RwLock&lt;HashSet&lt;Uuid&gt;&gt;,
    txn_id: Uuid,
    /**
     * Notifies the receiver that the pushTxn request has succeeded.
     * In other words, the pushee has finalized (aborted or committed)
     */
    sender: Arc&lt;Sender&lt;()&gt;&gt;,
    /**
     * The receiver will receive a message if the pushee's transaction
     * has finalized
     */
    pushee_finalized_receiver: Mutex&lt;Receiver&lt;()&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>WaitingPush</code> has a property called dependents that tracks the list of transactions that are blocked by the pusher’s transaction.</p>
<p>The <code>TxnWaitQueue</code> is a map from pushees’ transaction IDs to their lists of <code>Vec&lt;WaitingPush&gt;</code>.</p>
<p>The algorithm works as follows:</p>
<ul>
<li>a request performing a read or a write detects a conflicting lock so it queues itself to the lock. It starts a timer. If the timer times out before the lock is resolved, the request tries to push the transaction</li>
<li>the request pushes itself as a <code>WaitingPush</code> onto the txnWaitQueue. The request’s transaction is the pusher and the lock holder’s transaction is the pushee. The thread would then wait until either the pushee transaction has resolved or if it detects a cycle.</li>
<li>To detect a cycle, the pusher periodically queries for its own transitive dependents. Its transitive dependents are computed by looking up its own list of waitingPushes and each waitingPush’s dependents list. For example, if <code>txnA</code> queries for its dependents and the <code>txnWaitQueue</code> entry for <code>txnA</code> looks like this:</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>txnA: [
	waitingPush { txn: txnB, dependents: [txnC, txnD] },
	waitingPush { txn: txnE, dependents: [txnF] },
	waitingPush { txn: txnG, dependents: [txnH, txnI] }
]
<span class="boring">}</span></code></pre></pre>
<ul>
<li>then the <code>txnA</code>'s transitive dependents are <code>[txnB, txnC, ... txnH, txnI]</code>. If the pusher detects that its <code>pushee</code> is inside its transitive dependents, then a deadlock is detected as there is cyclic dependency. In that case, it tries to abort the <code>pushee</code>'s transaction.</li>
<li>If no deadlock is detected, the pusher updates its own <code>waitingPush</code>'s dependents to be its transitive dependents.</li>
</ul>
<p>Let’s see how we can use the algorithm to detect a deadlock with a basic example <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_control.go#L886">provided by CockroachDB</a>.</p>
<p>Let’s suppose the following happens:</p>
<ul>
<li>txnA enters txnB’s txnWaitQueue as a waitingPush</li>
<li>txnB enters txnC’s txnWaitQueue as a waitingPush</li>
<li>txnC enters txnA’s txnWaitQueue as a waitingPush</li>
</ul>
<pre><code>txnA: [
	waitingPush { txn: txnC, dependents: [] }
]
txnB: [
	waitingPush { txn: txnA, dependents: [] }
]
txnC: [
	waitingPush { txn: txnB, dependents: [] }
]
</code></pre>
<p>TxnA queries for its dependents and adds it to its waitingPush</p>
<pre><code>txnA: [
	waitingPush { txn: txnC, dependents: [] }
]
txnB: [
	waitingPush { txn: txnA, dependents: [txnC] }
]
txnC: [
	waitingPush { txn: txnB, dependents: [] }
]
</code></pre>
<p>TxnB queries for its dependents and adds it to its waitingPush</p>
<pre><code>txnA: [
	waitingPush { txn: txnC, dependents: [txnB] }
]
txnB: [
	waitingPush { txn: txnA, dependents: [txnC] }
]
txnC: [
	waitingPush { txn: txnB, dependents: [txnA, txnC] }
]
</code></pre>
<p>TxnB detects that txnC is both a dependent and the pushee, so a deadlock is detected.</p>
<p>From this example, we can see that the intuition behind this algorithm is that each <code>waitingPush</code>'s dependent lists keep growing until it detects its own <code>pushee</code> in its dependents list.</p>
<h3 id="txnwaitqueue-api"><a class="header" href="#txnwaitqueue-api">TxnWaitQueue API</a></h3>
<p>TxnWaitQueue’s API consists of two methods: wait_for_push and finalize_txn.</p>
<p><strong>wait_for_push: (pusher_txn_id, pushee_txn_id) → Result&lt;PushTxnResponse, WaitForPushError&gt;</strong></p>
<p>This method creates a waitingPush and adds it to its pushee’s waitQueue. It will then wait until either the pushee’s transaction is finalized or a deadlock is detected. To detect a cycle, it starts a separate thread that periodically queries for its dependents.</p>
<p><strong>finalize_txn: (txn_id) → ()</strong></p>
<p>This method is called when a transaction is resolved (aborted or committed). It removes the transaction from the txnWaitQueue and unblocks all pending waitingPushes.</p>
<h3 id="algorithm-implementation"><a class="header" href="#algorithm-implementation">Algorithm Implementation</a></h3>
<p>Inside Concurrency Manager’s <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L44">SequenceReq</a>, if it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L51">detects</a> that it needs to wait for a lock to be released, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#LL53C37-L53C51">calls wait_for</a> on the lock table. When wait_for is called, a timer is created. <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/lock_table/lock_table.rs#L266">If it times out</a> before the lock has been released, it calls <a href="https://github.com/brianshih1/little-key-value-db/blob/f239e62b5d97ff7754ce61e0f8ca02d889fcb4c2/src/txn_wait/txn_wait_queue.rs#L187">wait_for_push</a>.</p>
<p>After <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L197">pushing</a> the pusher onto the pushee’s wait queue, the pusher <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L198">begins to periodically query for its transitive dependents</a>.</p>
<p>The thread loops until either it detects that the pushee’s transaction has been resolved or a cycle is detected. To accomplish this, the thread <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L210">listens to two channels</a> with <code>tokio::select!</code>.</p>
<p>The first channel is created by <code>start_query_pusher_txn_dependents</code> which periodically queries for the pusher’s dependents and sends the message to this channel. <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L224">If a cycle is detected</a>, it aborts the pushee’s transaction by <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L227">sending</a> a <code>AbortTxn</code> request to the task queue.</p>
<p>The second channel is created when the <code>waitingPush</code> is <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L81">created</a>. When a transaction is aborted/committed, <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L155">finalize_txn</a> is called which would <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L160">loop through the waiting_pushes</a> and <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L102">send a message</a> to the <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/txn_wait/txn_wait_queue.rs#L246">receiver</a> which would terminate the function.</p>
<h3 id="cockroachdbs-implementation-2"><a class="header" href="#cockroachdbs-implementation-2">CockroachDB’s Implementation</a></h3>
<p>The TxnWaitQueue’s data structure and the algorithm to periodically query for the pusher’s transaction are based on CockroachDB’s txnWaitQueue implementation.</p>
<p>Inside <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/concurrency/concurrency_manager.go#L232">sequenceReqWithGuard</a>, if a conflicting lock is found, the concurrency manager calls <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/concurrency/concurrency_manager.go#L329">WaitOn</a>. If WaitOn <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/concurrency/lock_table_waiter.go#L346">times out</a> before the lock is released, the thread will try to <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/concurrency/lock_table_waiter.go#L378">push the transaction</a>.</p>
<p><a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L444">MaybeWaitForPush</a> would be called as a result. It <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L474">creates a waitingPush</a> and <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L478">pushes the pusher to the pushee’s waitingPushes</a>. It then <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L538">calls startQueryPusherTxn</a> which periodically <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L854">queries the pusher’s dependent list</a> and <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L885">sends the result via the created channel</a>.</p>
<p>WaitForPush listens to a few channels:</p>
<ul>
<li>The queryPusherCh, which is the channel created from <code>startQueryPusherTxn</code>. <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L664">When the queryPusherCh is signaled</a>, it first <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L665">checks if the transaction has been finalized</a>, and returns nil if it is. Otherwise, <code>waitForPush</code> <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L682">checks for the dependency cycle</a>. A pusher detects a cycle if the pushee’s txn ID is in its own dependents. <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L707">If there is a dependency, it aborts one of the transactions</a>.</li>
<li>The <a href="https://github.com/cockroachdb/cockroach/blob/c21c90f93219b857858518d25a8bc061444d573c/pkg/kv/kvserver/txnwait/queue.go#L593">pending channel</a> is a <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/txnwait/queue.go#L134">property on the waitingPush</a>. This channel receives an update whenever the pushee’s queue is cleared.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concurrency-manager"><a class="header" href="#concurrency-manager">Concurrency Manager</a></h1>
<p>Concurrency Manager is composed of a latch manager, a lock table, and a txnWaitQueue. Now that we better understand these individual components, we can finally look at how the Concurrency Manager’s API is implemented.</p>
<h3 id="concurrency-manager-api"><a class="header" href="#concurrency-manager-api">Concurrency Manager API</a></h3>
<p>The API is made up of two methods: sequence_req and finish_req.</p>
<p><strong>Sequence_req: (request) → Result&lt;Guard, SequenceReqError&gt;</strong></p>
<p><code>Sequence_req</code> provides isolation for the request by acquiring latches and waiting for conflicting locks to be released. Once <code>Sequence_req</code> returns a <code>Guard</code>, the request is guaranteed isolation until the guard is released.</p>
<p><strong>Finish_req: (guard) → ()</strong></p>
<p><code>Finish_req</code> is called when the request has finished executing. It releases the request from the components of the concurrency manager and allows blocked requests to proceed.</p>
<h3 id="implementation"><a class="header" href="#implementation">Implementation</a></h3>
<p><strong>Sequence_req</strong></p>
<p>Sequence_req first <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L45">figures out</a> the keys it needs to acquire latches and locks for. It then creates a <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L48">loop</a>. Each time it loops, it performs the following:</p>
<ul>
<li>it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L49">acquires the latches</a></li>
<li>it calls the lock table’s <code>scan_and_enqueue</code> method to see if there is a conflicting lock for one of the request’s keys
<ul>
<li>if <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L51">there is a conflicting lock</a>, the thread will <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L53">release the latches and wait until the lock is released</a>. After waiting, it will have become a <code>reservation</code> for the lock. In that case, it is free to re-acquire latches and rescan the lock table in the next iteration of the loop.</li>
<li>if there isn’t a conflicting lock, the function <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L64">stops looping and returns</a>.</li>
</ul>
</li>
</ul>
<p><strong>Finish_req</strong></p>
<p>Finish_req simply <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L76">releases the latches</a> and <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/concurrency/concurrency_manager.rs#L77">dequeues</a> acquired locks from the lock table.</p>
<h3 id="cockroachdbs-implementation-3"><a class="header" href="#cockroachdbs-implementation-3">CockroachDB’s Implementation</a></h3>
<p>The core idea behind CockroachDB’s <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_manager.go#L185">SequenceReq</a> implementation is similar to my implementation. The difference is that it has different modes, such as <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_control.go#L365">OptimisticEval</a> and <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_control.go#L363">PessimisticEval</a>. If the mode is OptimisticEval, it <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_manager.go#L270">calls</a> <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_control.go#LL498C2-L501C62">AcquireOptimistic</a> which does not wait for conflicting latches to be released. It needs to be followed with CheckOptimisticNoConflicts to ensure correctness.</p>
<p>My implementation is more similar to the pessimistic evaluation approach, which <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_manager.go#L276">acquires latches</a>.  CockroachDB’s SequenceReq then <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_manager.go#L320">calls ScanAndEnqueue</a> to find conflicting locks. If a conflicting lock <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_manager.go#L326">is found</a>, <a href="https://github.com/cockroachdb/cockroach/blob/530100fd39cc722bc324bfb3869a325622258fb3/pkg/kv/kvserver/concurrency/concurrency_manager.go#L330">WaitOn</a> is called, which waits until the lock is released or pushes the transaction if it times out.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="executing-the-request"><a class="header" href="#executing-the-request">Executing the Request</a></h1>
<p>During the lifetime of a request, the request can finally be executed after concurrency manager calls <code>sequence_req</code>.  In this section, we finally get to look at how the requests are executed. </p>
<p>These are the request types of the database:</p>
<ul>
<li>BeginTxn</li>
<li>CommitTxn</li>
<li>AbortTxn</li>
<li>Get</li>
<li>Put</li>
</ul>
<p>Each command needs to implement an <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L93">execute</a> method. Here are its implementations:</p>
<h3 id="begintxn"><a class="header" href="#begintxn">BeginTxn</a></h3>
<ul>
<li>BeginTxn simply <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L124">creates a transaction record</a> with the txn’s timestamp.</li>
</ul>
<h3 id="committxn"><a class="header" href="#committxn">CommitTxn</a></h3>
<ul>
<li>
<p>CommitTxn first <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L254">fetches the transaction record</a>.  If the transaction record is aborted, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L265">returns an error</a>.</p>
</li>
<li>
<p>Otherwise, it begins committing the transaction. Firstly, it needs to </p>
<p>perform a read refresh</p>
<p>to advance the read timestamp to the write timestamp. If you need a “refresher” on read refresh, look at </p>
<p>this page</p>
<p>.</p>
<ul>
<li>If the read refresh is unsuccessful, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L271">returns a ReadRefreshError</a>, which would restart the transaction.</li>
<li>If read refresh is successful, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L275">updates the transaction record</a> to be committed.</li>
</ul>
</li>
<li>
<p>Next, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#LL280C18-L280C41">resolves the uncommitted intent</a>, which replaces it with a proper MVCC key value with the transaction’s commit timestamp.</p>
</li>
<li>
<p>Next, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L281">releases the locks</a> held by the transaction</p>
</li>
<li>
<p>Finally, it <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L195">removes itself from the TxnWaitQueue</a> in case it was queued</p>
</li>
</ul>
<h3 id="aborttxn"><a class="header" href="#aborttxn">AbortTxn</a></h3>
<ul>
<li>AbortTxn first makes sure the transaction record <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L169">isn’t committed</a></li>
<li>Next, it <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L176">updates the transaction record to abort</a></li>
<li>It then <a href="https://github.com/brianshih1/little-key-value-db/blob/66f355d1a03c488c4f0aee5b8dc66796398bb4de/src/execute/request.rs#L181">removes all uncommitted intents</a> from the MVCC database</li>
<li>Next, it <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L281">releases the locks</a> held by the transaction</li>
<li>Finally, it <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L298">removes itself from the TxnWaitQueue</a> in case it was queued</li>
</ul>
<h3 id="get"><a class="header" href="#get">Get</a></h3>
<ul>
<li><a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L338">Get</a> first uses the read timestamp to <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L342">perform a mvcc_get</a> to retrieve the most recent value for the key.</li>
<li><a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L350">If mvcc_get returns an uncommitted intent</a>, it <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L351">checks</a> if the request’s transaction and the intent’s transaction are the same. In that case, the transaction is reading its uncommitted write so it can proceed.</li>
<li>Otherwise, Get <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L355">returns a WriteIntentError</a></li>
<li>Next, the function <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L365">adds the key to the read sets to the transaction</a> so that a read refresh can be performed later if the write timestamp gets bumped.</li>
<li>Finally, it returns the value.</li>
</ul>
<h3 id="put"><a class="header" href="#put">Put</a></h3>
<ul>
<li><a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L390">Put</a> uses <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L391">mvcc_put</a> to attempt to put an uncommitted intent into the database.</li>
<li>If mvcc_put is successful, it adds the uncommitted intent to the lock table by <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L404">calling acquire_lock</a></li>
<li>Otherwise, this means that an uncommitted intent was detected. Since there can only be one uncommitted intent for each key, the function <a href="https://github.com/brianshih1/little-key-value-db/blob/efa45d5873e6536a52e2f08270e693f45ecaaeba/src/execute/request.rs#L419">returns a WriteIntentError</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
